tuned_radmod03_sum <- summary(tuned_radmod03)
print(tuned_radmod03_sum)
print(paste0("Error promedio: ",tuned_radmod03_sum$performances$error %>% mean(),
". Desv. típica del error: ", tuned_radmod03_sum$performances$error %>% sd()))
} else {
tuned_radmod03 <- tune(svm ,Class ~ ., data = st_train, kernel = "radial",
ranges =list(cost=2**seq(from=-5, to=10),
gamma=2**seq(from=-5, to=10)),
tunecontrol = tune.control(cross=5))
saveRDS(tuned_radmod03,"../models/tuned/tuned_radmod03.Rds")
tuned_radmod03 <- readRDS("../models/tuned/tuned_radmod03.Rds")
print("Modelado refinado con kernel radial")
tuned_radmod03_sum <- summary(tuned_radmod03)
print(tuned_radmod03_sum)
print(paste0("Error promedio: ",tuned_radmod03_sum$performances$error %>% mean(),
". Desv. típica del error: ", tuned_radmod03_sum$performances$error %>% sd()))
}
tuned_radmod03
svmfit <- tuned_radmod03$best.model
plot(svmfit , st_train)
saved_dbs <- list.files("../dbs/model_db/")
if("df_final.Rds" %in% saved_dbs){
df_final <- readRDS(file="../dbs/model_db/df_final.Rds")
} else {
df_final$Class <- as.factor(df_final$Class)
saveRDS(df_final, file="../dbs/model_db/df_final.Rds")
}
# Creamos los conjuntos de entrenamiento y test
df_final$id <- 1:nrow(df_final)
set.seed(210)
train <- df_final %>% dplyr::sample_frac(.75)
test  <- dplyr::anti_join(df_final, train, by = 'id')
# Eliminamos la columna id
train <- train[,!(names(train) %in% c("id"))]
test <- test[,!(names(test) %in% c("id"))]
# Estandarizamos el conjunto de entrenamiento.
st_train <- scale(train[,1:(ncol(train)-1)],center = TRUE, scale = TRUE) %>% as.data.frame()
st_train$Class <- train$Class # Espero estar incluyendo la clase en el mismo orden. Revisar.
# Calculamos el vector de medias y el vector de desviaciones estándar del conjunto train.
means <- train %>% summarise_if(is.numeric, mean)
st.devs <- train %>% summarise_if(is.numeric, sd)
# Restamos las medias y dividimos por las desviaciones estándar
st_test <- scale(test[,1:(ncol(test)-1)],center = means, scale = st.devs) %>% as.data.frame()
st_test$Class <- test$Class
plot(svmfit , st_train)
plot(svmfit$ , st_train, Class~.)
plot(svmfit , st_train, Class~.)
plot(svmfit , data=st_train)
plot(svmfit , st_train, Class~.)
st_train %>% sapply(class)
st_train %>%  mutate_if(is.factor, funs(as.numeric(as.character(.))))
st_train$Class
st_train$Class %>% as.numeric()
st_train$Class %>% as.character() %>% as.numeric()
st_train$Class <- st_train$Class %>% as.numeric()
plot(svmfit , st_train, Class~.)
plot(svmfit , st_train, Class~Area + Perimeter)
plot(svmfit , st_train, st_train$Class~st_train$Area + st_train$Perimeter)
plot(svmfit , st_train, st_train$Class~st_train$Area + st_train$Perimeter+st_train$Major_Axis_Length+st_train$Minor_Axis_Length+st_train$Convex_Area)
tuned_radmod03$best.parameters
svmfit <-  svm(st_train$Class~., data=st_train, kernel ="radial",gamma =0.03125, cost=64)
plot(svmfit , st_train)
plot(svmfit , st_train)
plot(svmfit , st_train, st_train$Class~st_train$Area + st_train$Perimeter)
tuned_radmod03$best.parameters
tuned_radmod03$best.parameters$gamma
st_train$Class <- st_train$Class %>% as.numeric()
svmfit <-  svm(st_train$Class~., data=st_train,
kernel ="radial",
gamma =tuned_radmod03$best.parameters$gamma,
cost=tuned_radmod03$best.parameters$cost)
plot(svmfit , st_train)
plot(svmfit , st_train)
plot(svmfit , st_train)
p <- plot(svmfit , st_train)
print(p)
p <- plot(svmfit , st_train, formula = st_train$Class~.)
print(p)
?plot.svm
data(st_train)
st_train %>% data("bnr")
?data
p <- plot(svmfit , st_train, formula = Area~Perimeter)
p
p <- plot(svmfit , st_train, formula = st_train$Area~st_train$Perimeter)
p
setwd("~/Documents/MUM/MACE/2ndo Bloque/Entrega/source")
?svm
library(readxl)
library(dplyr)
library(knitr)
library(ggplot2)
library(ggpubr)
library(pastecs)
library(kableExtra)
library (e1071)
?svm
options(scipen=999) # desactivamos la notación científica
options(max.print=100) # limitamos la longitud de los print
df <- readxl::read_excel("../dbs/Pumpkin_Seeds_Dataset/Pumpkin_Seeds_Dataset.xlsx")
table(df$Class)
# Reemplazamos los outliers para cada clase
## Clase 1
Q1 <- quantile_df01['Q1',] %>% as.vector() %>% as.numeric()
Q3 <- quantile_df01['Q3',] %>% as.vector() %>% as.numeric()
P10 <- quantile_df01['P10',] %>% as.vector() %>% as.numeric()
P90 <- quantile_df01['P90',] %>% as.vector() %>% as.numeric()
top_IQR <- Q3+1.5*(Q3-Q1) #111027.750000
bot_IQR <- Q1-1.5*(Q3-Q1)
trimmed_df_class01 <- data.frame(df_class01)
perc_out01 <- c()
perc_mod01 <- c()
for(i in 1:(ncol(trimmed_df_class01)-1)) {
top_mod <- trimmed_df_class01[ , i][trimmed_df_class01[ , i] <= bot_IQR[i]]%>% length()
bot_mod <- trimmed_df_class01[ , i][trimmed_df_class01[ , i] >= top_IQR[i]]%>% length()
trimmed_df_class01[ , i][trimmed_df_class01[ , i] <= bot_IQR[i]] <- P10[i]
trimmed_df_class01[ , i][trimmed_df_class01[ , i] >= top_IQR[i]] <- P90[i]
count_top_out <- trimmed_df_class01[ , i]>=top_IQR[i] %>% as.vector()
count_bot_out <- trimmed_df_class01[ , i]<=bot_IQR[i] %>% as.vector()
perc_out01 <- c(perc_out01,100*(sum(count_top_out)+sum(count_bot_out))/(trimmed_df_class01 %>% nrow()))
perc_mod01 <- c(perc_mod01,100*(top_mod+bot_mod)/(trimmed_df_class01 %>% nrow()))
}# el vector perc_out representa el porcentaje de outliers de cada variable.
## Clase 2
Q1 <- quantile_df02['Q1',] %>% as.vector() %>% as.numeric()
Q3 <- quantile_df02['Q3',] %>% as.vector() %>% as.numeric()
P10 <- quantile_df02['P10',] %>% as.vector() %>% as.numeric()
P90 <- quantile_df02['P90',] %>% as.vector() %>% as.numeric()
top_IQR <- Q3+1.5*(Q3-Q1) #111027.750000
bot_IQR <- Q1-1.5*(Q3-Q1)
trimmed_df_class02 <- data.frame(df_class02)
perc_out02 <- c()
perc_mod02 <- c()
for(i in 1:(ncol(trimmed_df_class02)-1)) {
top_mod <- trimmed_df_class02[ , i][trimmed_df_class02[ , i] <= bot_IQR[i]]%>% length()
bot_mod <- trimmed_df_class02[ , i][trimmed_df_class02[ , i] >= top_IQR[i]]%>% length()
trimmed_df_class02[ , i][trimmed_df_class02[ , i] <= bot_IQR[i]] <- P10[i]
trimmed_df_class02[ , i][trimmed_df_class02[ , i] >= top_IQR[i]] <- P90[i]
count_top_out <- trimmed_df_class02[ , i]>=top_IQR[i] %>% as.vector()
count_bot_out <- trimmed_df_class02[ , i]<=bot_IQR[i] %>% as.vector()
perc_out02 <- c(perc_out02,100*(sum(count_top_out)+sum(count_bot_out))/(trimmed_df_class02 %>% nrow()))
perc_mod02 <- c(perc_mod02,100*(top_mod+bot_mod)/(trimmed_df_class02 %>% nrow()))
}# el vector perc_out representa el porcentaje de outliers de cada variable.
# Creamos el df final con todos los estadísticos para cada clase
## Calculamos los estadísticos para la clase 1
desc_df01 <- stat.desc(trimmed_df_class01[,-which(names(trimmed_df_class01) == "Class")]) %>% slice(., c(4,5,8,9,10,13))
## Añadimos los porcentajes de outliers y el porcentaje de valores modificados para el dataframe de la clase 1
perc_out_class01 <- data.frame(t(perc_out01))
colnames(perc_out_class01) <-  colnames(desc_df01)
rownames(perc_out_class01) <- c("perc.out") #
perc_mod_class01 <- data.frame(t(perc_mod01))
colnames(perc_mod_class01) <-  colnames(desc_df01)
rownames(perc_mod_class01) <- c("perc.mod") #
fn2='`perc.mod`: Es el porcentaje de valores modificados para cada variable.'
desc_class01 <- desc_df01 %>%  bind_rows(.,perc_out_class01) %>% bind_rows(.,perc_mod_class01)
desc_class01  %>% kbl() %>% kable_minimal("hover", full_width = F)%>%
footnote(number=c(fn2), number_title ="Estadísticos Clase Çerçevelik - Modificado", title_format = "bold") %>%  scroll_box(width = "auto")
## Calculamos los estadísticos para la clase 2
desc_df02 <- stat.desc(trimmed_df_class02[,-which(names(trimmed_df_class02) == "Class")]) %>% slice(., c(4,5,8,9,10,13))
## Añadimos los porcentajes de outliers para el dataframe de la clase 2
perc_out_class02 <- data.frame(t(perc_out02))
colnames(perc_out_class02) <-  colnames(desc_df02)
rownames(perc_out_class02) <- c("perc.out") #
perc_mod_class02 <- data.frame(t(perc_mod02))
colnames(perc_mod_class02) <-  colnames(desc_df02)
rownames(perc_mod_class02) <- c("perc.mod") #
desc_class02 <- desc_df02 %>%  bind_rows(.,perc_out_class02)%>% bind_rows(.,perc_mod_class02)
desc_class02  %>% kbl() %>% kable_minimal("hover", full_width = F)%>%
footnote(c(""),general_title="Estadísticos Clase Ürgüp Sivrisi - Modificado", title_format = "bold") %>%  scroll_box(width = "auto")
# Definimos un df para cada categoría
cat.vec <- df$Class %>% table() %>% names()
df_class01 <- df %>% filter(.,Class == cat.vec[1]) # Çerçevelik
df_class02 <- df %>% filter(.,Class == cat.vec[2]) # Ürgüp Sivrisi
# Calculamos los cuantiles para cada clase
## Clase 1
col_numeric <- which( sapply(df_class01, is.numeric ) ) # Creamos un selector de las columnas numéricas
quantile_df01 <- sapply(col_numeric, function( y ) {
quantile( x = unlist( df_class01[,  y ] ), c(.1,.25,.5,.75,.9))
}) %>% as.data.frame()
rownames(quantile_df01) <- c("P10","Q1","Q2","Q3","P90")
## Clase 2
col_numeric <- which( sapply(df_class02, is.numeric ) ) # Creamos un selector de las columnas numéricas
quantile_df02 <- sapply(col_numeric, function( y ) {
quantile( x = unlist( df_class02[,  y ] ), c(.1,.25,.5,.75,.9))
}) %>% as.data.frame()
rownames(quantile_df02) <- c("P10","Q1","Q2","Q3","P90")
# Calculamos el % de outliers para cada clase
## Clase 1
Q1 <- quantile_df01['Q1',] %>% as.vector() %>% as.numeric()
Q3 <- quantile_df01['Q3',] %>% as.vector() %>% as.numeric()
top_IQR <- Q3+1.5*(Q3-Q1) #111027.750000
bot_IQR <- Q1-1.5*(Q3-Q1)
k <- 1
perc_out01 <- c()
for(col in head(colnames(df_class01),-1)){
count_top_out <- df_class01[col]>=top_IQR[k] %>% as.vector()
count_bot_out <- df_class01[col]<=bot_IQR[k] %>% as.vector()
perc_out01 <- c(perc_out01,100*(sum(count_top_out)+sum(count_bot_out))/(df_class01 %>% nrow()))
k <- k+1
} # el vector perc_out representa el porcentaje de outliers de cada variable.
## Clase 2
Q1 <- quantile_df02['Q1',] %>% as.vector() %>% as.numeric()
Q3 <- quantile_df02['Q3',] %>% as.vector() %>% as.numeric()
top_IQR <- Q3+1.5*(Q3-Q1)
bot_IQR <- Q1-1.5*(Q3-Q1)
k <- 1
perc_out02 <- c()
for(col in head(colnames(df_class02),-1)){
count_top_out <- df_class02[col]>=top_IQR[k] %>% as.vector()
count_bot_out <- df_class02[col]<=bot_IQR[k] %>% as.vector()
perc_out02 <- c(perc_out02,100*(sum(count_top_out)+sum(count_bot_out))/(df_class02 %>% nrow()))
k <- k+1
} # el vector perc_out representa el porcentaje de outliers de cada variable.
# Creamos el df final con todos los estadísticos para cada clase
## Calculamos los estadísticos para la clase 1
desc_df01 <- stat.desc(df_class01[,-which(names(df_class01) == "Class")]) %>% slice(., c(4,5,8,9,10,13))
## Añadimos los porcentajes de outliers para el dataframe de la clase 1
perc_out_class01 <- data.frame(t(perc_out01))
colnames(perc_out_class01) <-  colnames(desc_df01)
rownames(perc_out_class01) <- c("perc.out") #
fn1='Más información sobre los principales estadísticos en `?pastecs::stat.desc`.'
fn2='`perc.out`: Es el porcentaje de outliers para cada variable, según el [criterio de Tukey](https://es.wikipedia.org/wiki/Diagrama_de_caja).'
desc_class01 <- desc_df01 %>%  bind_rows(.,perc_out_class01)
desc_class01  %>% kbl() %>% kable_minimal("hover", full_width = F)%>%
footnote(number=c(fn1,fn2), number_title="Estadísticos Clase Çerçevelik", title_format = "bold") %>%  scroll_box(width = "auto")
## Calculamos los estadísticos para la clase 2
desc_df02 <- stat.desc(df_class02[,-which(names(df_class02) == "Class")]) %>% slice(., c(4,5,8,9,10,13))
## Añadimos los porcentajes de outliers para el dataframe de la clase 2
perc_out_class02 <- data.frame(t(perc_out02))
colnames(perc_out_class02) <-  colnames(desc_df02)
rownames(perc_out_class02) <- c("perc.out") #
desc_class02 <- desc_df02 %>%  bind_rows(.,perc_out_class02)
desc_class02  %>% kbl() %>% kable_minimal("hover", full_width = F)%>%
footnote(c(""),general_title="Estadísticos Clase Ürgüp Sivrisi", title_format = "bold") %>%  scroll_box(width = "auto")
# Reemplazamos los outliers para cada clase
## Clase 1
Q1 <- quantile_df01['Q1',] %>% as.vector() %>% as.numeric()
Q3 <- quantile_df01['Q3',] %>% as.vector() %>% as.numeric()
P10 <- quantile_df01['P10',] %>% as.vector() %>% as.numeric()
P90 <- quantile_df01['P90',] %>% as.vector() %>% as.numeric()
top_IQR <- Q3+1.5*(Q3-Q1) #111027.750000
bot_IQR <- Q1-1.5*(Q3-Q1)
trimmed_df_class01 <- data.frame(df_class01)
perc_out01 <- c()
perc_mod01 <- c()
for(i in 1:(ncol(trimmed_df_class01)-1)) {
top_mod <- trimmed_df_class01[ , i][trimmed_df_class01[ , i] <= bot_IQR[i]]%>% length()
bot_mod <- trimmed_df_class01[ , i][trimmed_df_class01[ , i] >= top_IQR[i]]%>% length()
trimmed_df_class01[ , i][trimmed_df_class01[ , i] <= bot_IQR[i]] <- P10[i]
trimmed_df_class01[ , i][trimmed_df_class01[ , i] >= top_IQR[i]] <- P90[i]
count_top_out <- trimmed_df_class01[ , i]>=top_IQR[i] %>% as.vector()
count_bot_out <- trimmed_df_class01[ , i]<=bot_IQR[i] %>% as.vector()
perc_out01 <- c(perc_out01,100*(sum(count_top_out)+sum(count_bot_out))/(trimmed_df_class01 %>% nrow()))
perc_mod01 <- c(perc_mod01,100*(top_mod+bot_mod)/(trimmed_df_class01 %>% nrow()))
}# el vector perc_out representa el porcentaje de outliers de cada variable.
## Clase 2
Q1 <- quantile_df02['Q1',] %>% as.vector() %>% as.numeric()
Q3 <- quantile_df02['Q3',] %>% as.vector() %>% as.numeric()
P10 <- quantile_df02['P10',] %>% as.vector() %>% as.numeric()
P90 <- quantile_df02['P90',] %>% as.vector() %>% as.numeric()
top_IQR <- Q3+1.5*(Q3-Q1) #111027.750000
bot_IQR <- Q1-1.5*(Q3-Q1)
trimmed_df_class02 <- data.frame(df_class02)
perc_out02 <- c()
perc_mod02 <- c()
for(i in 1:(ncol(trimmed_df_class02)-1)) {
top_mod <- trimmed_df_class02[ , i][trimmed_df_class02[ , i] <= bot_IQR[i]]%>% length()
bot_mod <- trimmed_df_class02[ , i][trimmed_df_class02[ , i] >= top_IQR[i]]%>% length()
trimmed_df_class02[ , i][trimmed_df_class02[ , i] <= bot_IQR[i]] <- P10[i]
trimmed_df_class02[ , i][trimmed_df_class02[ , i] >= top_IQR[i]] <- P90[i]
count_top_out <- trimmed_df_class02[ , i]>=top_IQR[i] %>% as.vector()
count_bot_out <- trimmed_df_class02[ , i]<=bot_IQR[i] %>% as.vector()
perc_out02 <- c(perc_out02,100*(sum(count_top_out)+sum(count_bot_out))/(trimmed_df_class02 %>% nrow()))
perc_mod02 <- c(perc_mod02,100*(top_mod+bot_mod)/(trimmed_df_class02 %>% nrow()))
}# el vector perc_out representa el porcentaje de outliers de cada variable.
# Creamos el df final con todos los estadísticos para cada clase
## Calculamos los estadísticos para la clase 1
desc_df01 <- stat.desc(trimmed_df_class01[,-which(names(trimmed_df_class01) == "Class")]) %>% slice(., c(4,5,8,9,10,13))
## Añadimos los porcentajes de outliers y el porcentaje de valores modificados para el dataframe de la clase 1
perc_out_class01 <- data.frame(t(perc_out01))
colnames(perc_out_class01) <-  colnames(desc_df01)
rownames(perc_out_class01) <- c("perc.out") #
perc_mod_class01 <- data.frame(t(perc_mod01))
colnames(perc_mod_class01) <-  colnames(desc_df01)
rownames(perc_mod_class01) <- c("perc.mod") #
fn2='`perc.mod`: Es el porcentaje de valores modificados para cada variable.'
desc_class01 <- desc_df01 %>%  bind_rows(.,perc_out_class01) %>% bind_rows(.,perc_mod_class01)
desc_class01  %>% kbl() %>% kable_minimal("hover", full_width = F)%>%
footnote(number=c(fn2), number_title ="Estadísticos Clase Çerçevelik - Modificado", title_format = "bold") %>%  scroll_box(width = "auto")
## Calculamos los estadísticos para la clase 2
desc_df02 <- stat.desc(trimmed_df_class02[,-which(names(trimmed_df_class02) == "Class")]) %>% slice(., c(4,5,8,9,10,13))
## Añadimos los porcentajes de outliers para el dataframe de la clase 2
perc_out_class02 <- data.frame(t(perc_out02))
colnames(perc_out_class02) <-  colnames(desc_df02)
rownames(perc_out_class02) <- c("perc.out") #
perc_mod_class02 <- data.frame(t(perc_mod02))
colnames(perc_mod_class02) <-  colnames(desc_df02)
rownames(perc_mod_class02) <- c("perc.mod") #
desc_class02 <- desc_df02 %>%  bind_rows(.,perc_out_class02)%>% bind_rows(.,perc_mod_class02)
desc_class02  %>% kbl() %>% kable_minimal("hover", full_width = F)%>%
footnote(c(""),general_title="Estadísticos Clase Ürgüp Sivrisi - Modificado", title_format = "bold") %>%  scroll_box(width = "auto")
# Creación de la base de datos para el modelado.
df_final <- trimmed_df_class01 %>% bind_rows(.,trimmed_df_class02)
saved_dbs <- list.files("../dbs/model_db/")
if("df_final.Rds" %in% saved_dbs){
df_final <- readRDS(file="../dbs/model_db/df_final.Rds")
} else {
df_final$Class <- as.factor(df_final$Class)
saveRDS(df_final, file="../dbs/model_db/df_final.Rds")
}
# Creamos los conjuntos de entrenamiento y test
df_final$id <- 1:nrow(df_final)
set.seed(210)
train <- df_final %>% dplyr::sample_frac(.75)
test  <- dplyr::anti_join(df_final, train, by = 'id')
# Eliminamos la columna id
train <- train[,!(names(train) %in% c("id"))]
test <- test[,!(names(test) %in% c("id"))]
# Listado de modelos iniciales guardados
saved_models <- list.files("../models/base/")
# Modelado inicial con kernel lineal
if("tuned_linmod01.Rds" %in% saved_models){
tuned_linmod01 <- readRDS("../models/base/tuned_linmod01.Rds")
print("Modelado inicial con kernel lineal")
tuned_linmod01_sum <- summary(tuned_linmod01)
tuned_linmod01_sum %>% print()
print(paste0("Error promedio: ",tuned_linmod01_sum$performances$error %>% mean(),
". Desv. típica del error: ", tuned_linmod01_sum$performances$error %>% sd()))
} else {
tuned_linmod01 <- tune(svm ,Class ~ ., data = train, kernel = "linear",
ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100) ),
tunecontrol = tune.control(cross=10))
saveRDS(tuned_linmod01,"../models/base/tuned_linmod01.Rds")
tuned_linmod01 <- readRDS("../models/base/tuned_linmod01.Rds")
print("Modelado inicial con kernel lineal")
tuned_linmod01_sum <- summary(tuned_linmod01)
tuned_linmod01_sum %>% print()
print(paste0("Error promedio: ",tuned_linmod01_sum$performances$error %>% mean(),
". Desv. típica del error: ", tuned_linmod01_sum$performances$error %>% sd()))
}
# Modelado inicial con kernel polinomial
if("tuned_polymod01.Rds" %in% saved_models){
tuned_polymod01 <- readRDS("../models/base/tuned_polymod01.Rds")
print("Modelado inicial con kernel polinomial")
tuned_polymod01_sum <- summary(tuned_polymod01)
print(tuned_polymod01_sum)
print(paste0("Error promedio: ",tuned_polymod01_sum$performances$error %>% mean(),
". Desv. típica del error: ", tuned_polymod01_sum$performances$error %>% sd()))
} else {
tuned_polymod01 <- tune(svm ,Class ~ ., data = train, kernel = "polynomial",
ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100) ),
degree = 3,
tunecontrol = tune.control(cross=10))
saveRDS(tuned_polymod01,"../models/base/tuned_polymod01.Rds")
tuned_polymod01 <- readRDS("../models/base/tuned_polymod01.Rds")
print("Modelado inicial con kernel polinomial")
tuned_polymod01_sum <- summary(tuned_polymod01)
print(tuned_polymod01_sum)
print(paste0("Error promedio: ",tuned_polymod01_sum$performances$error %>% mean(),
". Desv. típica del error: ", tuned_polymod01_sum$performances$error %>% sd()))
}
# Modelado inicial con kernel radial
if("tuned_radmod01.Rds" %in% saved_models){
tuned_radmod01 <- readRDS("../models/base/tuned_radmod01.Rds")
print("Modelado inicial con kernel radial")
tuned_radmod01_sum <- summary(tuned_radmod01)
print(tuned_radmod01_sum)
print(paste0("Error promedio: ",tuned_radmod01_sum$performances$error %>% mean(),
". Desv. típica del error: ", tuned_radmod01_sum$performances$error %>% sd()))
} else {
tuned_radmod01 <- tune(svm ,Class ~ ., data = train, kernel = "radial",
ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100) ),
tunecontrol = tune.control(cross=10))
saveRDS(tuned_radmod01,"../models/base/tuned_radmod01.Rds")
tuned_radmod01 <- readRDS("../models/base/tuned_radmod01.Rds")
print("Modelado inicial con kernel radial")
tuned_radmod01_sum <- summary(tuned_radmod01)
print(tuned_radmod01_sum)
print(paste0("Error promedio: ",tuned_radmod01_sum$performances$error %>% mean(),
". Desv. típica del error: ", tuned_radmod01_sum$performances$error %>% sd()))
}
# Modelado inicial con kernel sigmoidal
if("tuned_sigmod01.Rds" %in% saved_models){
tuned_sigmod01 <- readRDS("../models/base/tuned_sigmod01.Rds")
print("Modelado inicial con kernel sigmoidal")
tuned_sigmod01_sum <- summary(tuned_sigmod01)
print(tuned_sigmod01_sum)
print(paste0("Error promedio: ",tuned_sigmod01_sum$performances$error %>% mean(),
". Desv. típica del error: ", tuned_sigmod01_sum$performances$error %>% sd()))
} else {
tuned_sigmod01 <- tune(svm ,Class ~ ., data = train, kernel = "sigmoid",
ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100) ),
tunecontrol = tune.control(cross=10))
saveRDS(tuned_sigmod01,"../models/base/tuned_sigmod01.Rds")
tuned_sigmod01 <- readRDS("../models/base/tuned_sigmod01.Rds")
print("Modelado inicial con kernel sigmoidal")
tuned_sigmod01_sum <- summary(tuned_sigmod01)
print(tuned_sigmod01_sum)
print(paste0("Error promedio: ",tuned_sigmod01_sum$performances$error %>% mean(),
". Desv. típica del error: ", tuned_sigmod01_sum$performances$error %>% sd()))
}
# Listado de modelos tuneados guardados
saved_models <- list.files("../models/tuned/")
# Modelado con kernel lineal
if("tuned_linmod02.Rds" %in% saved_models){
tuned_linmod02 <- readRDS("../models/tuned/tuned_linmod02.Rds")
print("Modelado con kernel lineal")
tuned_linmod02_sum <- summary(tuned_linmod02)
tuned_linmod02_sum %>% print()
print(paste0("Error promedio: ",tuned_linmod02_sum$performances$error %>% mean(),
". Desv. típica del error: ", tuned_linmod02_sum$performances$error %>% sd()))
} else {
tuned_linmod02 <- tune(svm ,Class ~ ., data = train, kernel = "linear",
ranges =list(cost=seq(from = 1, to = 10, by=0.25) ),
tunecontrol = tune.control(cross=10))
saveRDS(tuned_linmod02,"../models/tuned/tuned_linmod02.Rds")
tuned_linmod01 <- readRDS("../models/tuned/tuned_linmod02.Rds")
print("Modelado con kernel lineal")
tuned_linmod02_sum <- summary(tuned_linmod02)
tuned_linmod02_sum %>% print()
print(paste0("Error promedio: ",tuned_linmod02_sum$performances$error %>% mean(),
". Desv. típica del error: ", tuned_linmod02_sum$performances$error %>% sd()))
}
# Modelado con kernel radial
if("tuned_radmod02.Rds" %in% saved_models){
tuned_radmod02 <- readRDS("../models/tuned/tuned_radmod02.Rds")
print("Modelado con kernel radial")
tuned_radmod02_sum <- summary(tuned_radmod02)
print(tuned_radmod02_sum)
print(paste0("Error promedio: ",tuned_radmod02_sum$performances$error %>% mean(),
". Desv. típica del error: ", tuned_radmod02_sum$performances$error %>% sd()))
} else {
tuned_radmod02 <- tune(svm ,Class ~ ., data = train, kernel = "radial",
ranges =list(cost=seq(from = 5, to = 10, by=0.5),
gamma=seq(from = 0.1, to = 5, by=0.2) ),
tunecontrol = tune.control(cross=10))
saveRDS(tuned_radmod02,"../models/tuned/tuned_radmod02.Rds")
tuned_radmod02 <- readRDS("../models/tuned/tuned_radmod02.Rds")
print("Modelado con kernel radial")
tuned_radmod02_sum <- summary(tuned_radmod02)
print(tuned_radmod02_sum)
print(paste0("Error promedio: ",tuned_radmod02_sum$performances$error %>% mean(),
". Desv. típica del error: ", tuned_radmod02_sum$performances$error %>% sd()))
}
# Estandarizamos el conjunto de entrenamiento.
st_train <- scale(train[,1:(ncol(train)-1)],center = TRUE, scale = TRUE) %>% as.data.frame()
st_train$Class <- train$Class # Espero estar incluyendo la clase en el mismo orden. Revisar.
# Calculamos el vector de medias y el vector de desviaciones estándar del conjunto train.
means <- train %>% summarise_if(is.numeric, mean)
st.devs <- train %>% summarise_if(is.numeric, sd)
# Restamos las medias y dividimos por las desviaciones estándar
st_test <- scale(test[,1:(ncol(test)-1)],center = means, scale = st.devs) %>% as.data.frame()
st_test$Class <- test$Class
# Modelado refinado con kernel radial
if("tuned_radmod03.Rds" %in% saved_models){
tuned_radmod03 <- readRDS("../models/tuned/tuned_radmod03.Rds")
print("Modelado refinado con kernel radial")
tuned_radmod03_sum <- summary(tuned_radmod03)
print(tuned_radmod03_sum)
print(paste0("Error promedio: ",tuned_radmod03_sum$performances$error %>% mean(),
". Desv. típica del error: ", tuned_radmod03_sum$performances$error %>% sd()))
} else {
tuned_radmod03 <- tune(svm ,Class ~ ., data = st_train, kernel = "radial",
ranges =list(cost=2**seq(from=-5, to=10),
gamma=2**seq(from=-5, to=10)),
tunecontrol = tune.control(cross=5))
saveRDS(tuned_radmod03,"../models/tuned/tuned_radmod03.Rds")
tuned_radmod03 <- readRDS("../models/tuned/tuned_radmod03.Rds")
print("Modelado refinado con kernel radial")
tuned_radmod03_sum <- summary(tuned_radmod03)
print(tuned_radmod03_sum)
print(paste0("Error promedio: ",tuned_radmod03_sum$performances$error %>% mean(),
". Desv. típica del error: ", tuned_radmod03_sum$performances$error %>% sd()))
}
T=table(true=st_test[,"Class"], pred=predict (tuned_radmod03$best.model,st_test))
T
install.packages("cvms")
install.packages("recipes")
install.packages("cvms")
library(cvms)
confussion_table = table(true = st_test[,"Class"],
pred = predict(tuned_radmod03$best.model,st_test))
plot_confusion_matrix(confussion_table)
plot_confusion_matrix(confussion_table %>% as.data.frame())
confussion_table
confussion_table$true
confussion_table = table(Target = st_test[,"Class"],
Prediction = predict(tuned_radmod03$best.model,st_test))
plot_confusion_matrix(confussion_table %>% as.data.frame())
test <- confussion_table %>% as.data.frame()
colnames(test)
test %>% View()
?confusion_matrix
confusion_table = confusion_table(targets = st_test[,"Class"],
predictions = predict(tuned_radmod03$best.model,st_test))
confusion_table = confusion_matrix(targets = st_test[,"Class"],
predictions = predict(tuned_radmod03$best.model,st_test))
confusion_table %>% View()
plot_confusion_matrix(confussion_table)
plot_confusion_matrix(confussion_table %>% as.data.frame())
plot_confusion_matrix(confussion_table$`Confusion Matrix`[[1]])
confusion_table %>% View
plot_confusion_matrix(confusion_table$`Confusion Matrix`[[1]])
?plot_confusion_matrix
install.packages(c("ggimage","rsvg"))
plot_confusion_matrix(confusion_table$`Confusion Matrix`[[1]])
plot_confusion_matrix(confusion_table$`Confusion Matrix`[[1]], palette = "Greens")
plot_confusion_matrix(confusion_table$`Confusion Matrix`[[1]], palette = "Oranges")
plot_confusion_matrix(confusion_table$`Confusion Matrix`[[1]], palette = "Greys")
plot_confusion_matrix(confusion_table$`Confusion Matrix`[[1]], palette = "Purples")
plot_confusion_matrix(confusion_table$`Confusion Matrix`[[1]], palette = "Reds")
plot_confusion_matrix(confusion_table$`Confusion Matrix`[[1]], palette = "Oranges")
plot_confusion_matrix(confusion_table$`Confusion Matrix`[[1]], palette = "Greens")
