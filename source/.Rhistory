?knit
?rmarkdown::render
library(e1071)
library(readxl)
library(dplyr)
library(knitr)
library(ggplot2)
library(ggpubr)
library(pastecs)
library(kableExtra)
library (e1071)
options(scipen=999) # desactivamos la notación científica
df <- readxl::read_excel("../dbs/Pumpkin_Seeds_Dataset/Pumpkin_Seeds_Dataset.xlsx")
table(df$Class)
# Definimos un df para cada categoría
cat.vec <- df$Class %>% table() %>% names()
df_class01 <- df %>% filter(.,Class == cat.vec[1]) # Çerçevelik
df_class02 <- df %>% filter(.,Class == cat.vec[2]) # Ürgüp Sivrisi
# Calculamos los cuantiles para cada clase
## Clase 1
col_numeric <- which( sapply(df_class01, is.numeric ) ) # Creamos un selector de las columnas numéricas
quantile_df01 <- sapply(col_numeric, function( y ) {
quantile( x = unlist( df_class01[,  y ] ), c(.1,.25,.5,.75,.9))
}) %>% as.data.frame()
rownames(quantile_df01) <- c("P10","Q1","Q2","Q3","P90")
## Clase 2
col_numeric <- which( sapply(df_class02, is.numeric ) ) # Creamos un selector de las columnas numéricas
quantile_df02 <- sapply(col_numeric, function( y ) {
quantile( x = unlist( df_class02[,  y ] ), c(.1,.25,.5,.75,.9))
}) %>% as.data.frame()
rownames(quantile_df02) <- c("P10","Q1","Q2","Q3","P90")
# Calculamos el % de outliers para cada clase
## Clase 1
Q1 <- quantile_df01['Q1',] %>% as.vector() %>% as.numeric()
Q3 <- quantile_df01['Q3',] %>% as.vector() %>% as.numeric()
top_IQR <- Q3+1.5*(Q3-Q1) #111027.750000
bot_IQR <- Q1-1.5*(Q3-Q1)
k <- 1
perc_out01 <- c()
for(col in head(colnames(df_class01),-1)){
count_top_out <- df_class01[col]>=top_IQR[k] %>% as.vector()
count_bot_out <- df_class01[col]<=bot_IQR[k] %>% as.vector()
perc_out01 <- c(perc_out01,100*(sum(count_top_out)+sum(count_bot_out))/(df_class01 %>% nrow()))
k <- k+1
} # el vector perc_out representa el porcentaje de outliers de cada variable.
## Clase 2
Q1 <- quantile_df02['Q1',] %>% as.vector() %>% as.numeric()
Q3 <- quantile_df02['Q3',] %>% as.vector() %>% as.numeric()
top_IQR <- Q3+1.5*(Q3-Q1)
bot_IQR <- Q1-1.5*(Q3-Q1)
k <- 1
perc_out02 <- c()
for(col in head(colnames(df_class02),-1)){
count_top_out <- df_class02[col]>=top_IQR[k] %>% as.vector()
count_bot_out <- df_class02[col]<=bot_IQR[k] %>% as.vector()
perc_out02 <- c(perc_out02,100*(sum(count_top_out)+sum(count_bot_out))/(df_class02 %>% nrow()))
k <- k+1
} # el vector perc_out representa el porcentaje de outliers de cada variable.
# Creamos el df final con todos los estadísticos para cada clase
## Calculamos los estadísticos para la clase 1
desc_df01 <- stat.desc(df_class01[,-which(names(df_class01) == "Class")]) %>% slice(., c(4,5,8,9,10,13))
## Añadimos los porcentajes de outliers para el dataframe de la clase 1
perc_out_class01 <- data.frame(t(perc_out01))
colnames(perc_out_class01) <-  colnames(desc_df01)
rownames(perc_out_class01) <- c("perc.out") #
fn1='Más información sobre los principales estadísticos en `?pastecs::stat.desc`.'
fn2='`perc.out`: Es el porcentaje de outliers para cada variable, según el [criterio de Tukey](https://es.wikipedia.org/wiki/Diagrama_de_caja).'
desc_class01 <- desc_df01 %>%  bind_rows(.,perc_out_class01)
desc_class01  %>% kbl() %>% kable_minimal("hover", full_width = F)%>%
footnote(number=c(fn1,fn2), number_title="Estadísticos Clase Çerçevelik", title_format = "bold") %>%  scroll_box(width = "auto")
## Calculamos los estadísticos para la clase 2
desc_df02 <- stat.desc(df_class02[,-which(names(df_class02) == "Class")]) %>% slice(., c(4,5,8,9,10,13))
## Añadimos los porcentajes de outliers para el dataframe de la clase 2
perc_out_class02 <- data.frame(t(perc_out02))
colnames(perc_out_class02) <-  colnames(desc_df02)
rownames(perc_out_class02) <- c("perc.out") #
desc_class02 <- desc_df02 %>%  bind_rows(.,perc_out_class02)
desc_class02  %>% kbl() %>% kable_minimal("hover", full_width = F)%>%
footnote(c(""),general_title="Estadísticos Clase Ürgüp Sivrisi", title_format = "bold") %>%  scroll_box(width = "auto")
# Reemplazamos los outliers para cada clase
## Clase 1
Q1 <- quantile_df01['Q1',] %>% as.vector() %>% as.numeric()
Q3 <- quantile_df01['Q3',] %>% as.vector() %>% as.numeric()
P10 <- quantile_df01['P10',] %>% as.vector() %>% as.numeric()
P90 <- quantile_df01['P90',] %>% as.vector() %>% as.numeric()
top_IQR <- Q3+1.5*(Q3-Q1) #111027.750000
bot_IQR <- Q1-1.5*(Q3-Q1)
trimmed_df_class01 <- data.frame(df_class01)
perc_out01 <- c()
perc_mod01 <- c()
for(i in 1:(ncol(trimmed_df_class01)-1)) {
top_mod <- trimmed_df_class01[ , i][trimmed_df_class01[ , i] <= bot_IQR[i]]%>% length()
bot_mod <- trimmed_df_class01[ , i][trimmed_df_class01[ , i] >= top_IQR[i]]%>% length()
trimmed_df_class01[ , i][trimmed_df_class01[ , i] <= bot_IQR[i]] <- P10[i]
trimmed_df_class01[ , i][trimmed_df_class01[ , i] >= top_IQR[i]] <- P90[i]
count_top_out <- trimmed_df_class01[ , i]>=top_IQR[i] %>% as.vector()
count_bot_out <- trimmed_df_class01[ , i]<=bot_IQR[i] %>% as.vector()
perc_out01 <- c(perc_out01,100*(sum(count_top_out)+sum(count_bot_out))/(trimmed_df_class01 %>% nrow()))
perc_mod01 <- c(perc_mod01,100*(top_mod+bot_mod)/(trimmed_df_class01 %>% nrow()))
}# el vector perc_out representa el porcentaje de outliers de cada variable.
## Clase 2
Q1 <- quantile_df02['Q1',] %>% as.vector() %>% as.numeric()
Q3 <- quantile_df02['Q3',] %>% as.vector() %>% as.numeric()
P10 <- quantile_df02['P10',] %>% as.vector() %>% as.numeric()
P90 <- quantile_df02['P90',] %>% as.vector() %>% as.numeric()
top_IQR <- Q3+1.5*(Q3-Q1) #111027.750000
bot_IQR <- Q1-1.5*(Q3-Q1)
trimmed_df_class02 <- data.frame(df_class02)
perc_out02 <- c()
perc_mod02 <- c()
for(i in 1:(ncol(trimmed_df_class02)-1)) {
top_mod <- trimmed_df_class02[ , i][trimmed_df_class02[ , i] <= bot_IQR[i]]%>% length()
bot_mod <- trimmed_df_class02[ , i][trimmed_df_class02[ , i] >= top_IQR[i]]%>% length()
trimmed_df_class02[ , i][trimmed_df_class02[ , i] <= bot_IQR[i]] <- P10[i]
trimmed_df_class02[ , i][trimmed_df_class02[ , i] >= top_IQR[i]] <- P90[i]
count_top_out <- trimmed_df_class02[ , i]>=top_IQR[i] %>% as.vector()
count_bot_out <- trimmed_df_class02[ , i]<=bot_IQR[i] %>% as.vector()
perc_out02 <- c(perc_out02,100*(sum(count_top_out)+sum(count_bot_out))/(trimmed_df_class02 %>% nrow()))
perc_mod02 <- c(perc_mod02,100*(top_mod+bot_mod)/(trimmed_df_class02 %>% nrow()))
}# el vector perc_out representa el porcentaje de outliers de cada variable.
# Creamos el df final con todos los estadísticos para cada clase
## Calculamos los estadísticos para la clase 1
desc_df01 <- stat.desc(trimmed_df_class01[,-which(names(trimmed_df_class01) == "Class")]) %>% slice(., c(4,5,8,9,10,13))
## Añadimos los porcentajes de outliers y el porcentaje de valores modificados para el dataframe de la clase 1
perc_out_class01 <- data.frame(t(perc_out01))
colnames(perc_out_class01) <-  colnames(desc_df01)
rownames(perc_out_class01) <- c("perc.out") #
perc_mod_class01 <- data.frame(t(perc_mod01))
colnames(perc_mod_class01) <-  colnames(desc_df01)
rownames(perc_mod_class01) <- c("perc.mod") #
fn2='`perc.mod`: Es el porcentaje de valores modificados para cada variable.'
desc_class01 <- desc_df01 %>%  bind_rows(.,perc_out_class01) %>% bind_rows(.,perc_mod_class01)
desc_class01  %>% kbl() %>% kable_minimal("hover", full_width = F)%>%
footnote(number=c(fn2), number_title ="Estadísticos Clase Çerçevelik - Modificado", title_format = "bold") %>%  scroll_box(width = "auto")
## Calculamos los estadísticos para la clase 2
desc_df02 <- stat.desc(trimmed_df_class02[,-which(names(trimmed_df_class02) == "Class")]) %>% slice(., c(4,5,8,9,10,13))
## Añadimos los porcentajes de outliers para el dataframe de la clase 2
perc_out_class02 <- data.frame(t(perc_out02))
colnames(perc_out_class02) <-  colnames(desc_df02)
rownames(perc_out_class02) <- c("perc.out") #
perc_mod_class02 <- data.frame(t(perc_mod02))
colnames(perc_mod_class02) <-  colnames(desc_df02)
rownames(perc_mod_class02) <- c("perc.mod") #
desc_class02 <- desc_df02 %>%  bind_rows(.,perc_out_class02)%>% bind_rows(.,perc_mod_class02)
desc_class02  %>% kbl() %>% kable_minimal("hover", full_width = F)%>%
footnote(c(""),general_title="Estadísticos Clase Ürgüp Sivrisi - Modificado", title_format = "bold") %>%  scroll_box(width = "auto")
# Creación de la base de datos para el modelado.
df_final <- trimmed_df_class01 %>% bind_rows(.,trimmed_df_class02)
df_final %>% ncol()
df_final %>% nrow()
df_final %>% View()
df %>% sapply(class) %>% kable(.,col.names = c("Tipo"))
df %>% sapply(class) %>% kable(.,col.names = c("Tipo"))
df %>% sapply(class) %>% View()
df_final %>% sapply(class) %>% View()
df_final$Class <- as.factor(df_final$Class)
df_final %>% sapply(class) %>% View()
?svm
df_final$Class <- as.factor(df_final$Class)
m <- svm(Class ~ ., data = df_final, kernel = "linear")
summary(m)
plot(m , df_final)
tuned_linmod01 <- tune(svm ,Class ~ ., data = df_final, kernel = "linear",
ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100) ),
tunecontrol = tune.control(cross=10))
summary(tuned_linmod01)
summary(tuned_linmod01)
?seq
?tune
tuned_linmod01
tuned_linmod01$train.ind
tuned_linmod01$train.ind %>% View()
?svm
# Modelado inicial con kernel lineal
tuned_linmod01 <- tune(svm ,Class ~ ., data = df_final, kernel = "linear",
ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100) ),
tunecontrol = tune.control(cross=10))
summary(tuned_linmod01)
# Modelado inicial con kernel polinomial
tuned_polymod01 <- tune(svm ,Class ~ ., data = df_final, kernel = "polynomial",
ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100) ),
degree = 3,
tunecontrol = tune.control(cross=10))
summary(tuned_polymod01)
tuned_polymod01
tuned_polymod01
summary(tuned_polymod01)
# Modelado inicial con kernel lineal
tuned_linmod01 <- tune(svm ,Class ~ ., data = df_final, kernel = "linear",
ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100) ),
tunecontrol = tune.control(cross=10))
# Modelado inicial con kernel lineal
# tuned_linmod01 <- tune(svm ,Class ~ ., data = df_final, kernel = "linear",
#                        ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100) ),
#                        tunecontrol = tune.control(cross=10))
summary(tuned_linmod01)
# Modelado inicial con kernel polinomial
# tuned_polymod01 <- tune(svm ,Class ~ ., data = df_final, kernel = "polynomial",
#                        ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100) ),
#                        degree = 3,
#                        tunecontrol = tune.control(cross=10))
summary(tuned_polymod01)
summary(tuned_polymod01)
# Modelado inicial con kernel lineal
tuned_linmod01 <- tune(svm ,Class ~ ., data = df_final, kernel = "linear",
ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100) ),
tunecontrol = tune.control(cross=10))
summary(tuned_linmod01)
# Modelado inicial con kernel polinomial
tuned_polymod01 <- tune(svm ,Class ~ ., data = df_final, kernel = "polynomial",
ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100) ),
degree = c(2,3,4,5),
tunecontrol = tune.control(cross=10))
summary(tuned_polymod01)
summary(tuned_polymod01)
summary(tuned_linmod01)
summary(tuned_linmod01) %>% View()
summary(tuned_linmod01) %>% print()
# Modelado inicial con kernel lineal
tuned_linmod01 <- tune(svm ,Class ~ ., data = df_final, kernel = "linear",
ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100) ),
tunecontrol = tune.control(cross=10))
summary(tuned_linmod01) %>% print()
# Modelado inicial con kernel polinomial
tuned_polymod01 <- tune(svm ,Class ~ ., data = df_final, kernel = "polynomial",
ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100) ),
degree = c(2,3,4,5),
tunecontrol = tune.control(cross=10))
summary(tuned_polymod01) %>% print()
# Modelado inicial con kernel lineal
tuned_linmod01 <- tune(svm ,Class ~ ., data = df_final, kernel = "linear",
ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100) ),
tunecontrol = tune.control(cross=10))
summary(tuned_linmod01) %>% print()
# Modelado inicial con kernel polinomial
tuned_polymod01 <- tune(svm ,Class ~ ., data = df_final, kernel = "polynomial",
ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100) ),
degree = 3,
tunecontrol = tune.control(cross=10))
summary(tuned_polymod01) %>% print()
# Modelado inicial con kernel radial
tuned_radmod01 <- tune(svm ,Class ~ ., data = df_final, kernel = "radial basis",
ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100) ),
tunecontrol = tune.control(cross=10))
# Modelado inicial con kernel lineal
tuned_linmod01 <- tune(svm ,Class ~ ., data = df_final, kernel = "linear",
ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100) ),
tunecontrol = tune.control(cross=10))
summary(tuned_linmod01) %>% print()
# Modelado inicial con kernel polinomial
tuned_polymod01 <- tune(svm ,Class ~ ., data = df_final, kernel = "polynomial",
ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100) ),
degree = 3,
tunecontrol = tune.control(cross=10))
summary(tuned_polymod01) %>% print()
# Modelado inicial con kernel radial
tuned_radmod01 <- tune(svm ,Class ~ ., data = df_final, kernel = "radial",
ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100) ),
tunecontrol = tune.control(cross=10))
summary(tuned_radmod01) %>% print()
# Modelado inicial con kernel radial
tuned_sigmod01 <- tune(svm ,Class ~ ., data = df_final, kernel = "sigmoid",
ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100) ),
tunecontrol = tune.control(cross=10))
summary(tuned_sigmod01) %>% print()
install.packages("rmdformats")
?tune
setwd("~/Documents/MUM/MACE/2ndo Bloque/Entrega/source")
write.svm(tuned_linmod01, svm.file = "../models/Rdata.svm",scale.file = "./models/Rdata.scale", yscale.file = "./models/Rdata.yscale")
best.tune(tuned_linmod01)
tuned_linmod01$best.performance
tuned_linmod01$best.parameters %>% View()
summary((tuned_linmod01))
saveRDS(tuned_linmod01,"../models/tuned_linmod01.Rds")
setwd("~/Documents/MUM/MACE/2ndo Bloque/Entrega/source")
saveRDS(tuned_linmod01,"../models/tuned_linmod01.Rds")
t <- readRDS("../models/tuned_linmod01.Rds")
summary(t)
?cbind
y <- if(3<4) 1 else 2
y
str(tuned_linmod01)
list.files("../models/")
"tuned_linmod01.Rds" in list.files("../models/")
"tuned_linmod01.Rds" %in% list.files("../models/")
"tuned_linmod01.Rds" %in% list.files("../models/base")
"tuned_linmod01.Rds" %in% list.files("../models/base/")
t <- load("../models/base/tuned_linmod01.Rds")
t <- readRDS("../models/base/tuned_linmod01.Rds")
t
summary(t)
# Listado de modelos iniciales guardados
saved_models <- list.files("../models/base/")
# Modelado inicial con kernel lineal
if("tuned_linmod01.Rds" %in% list.files("../models/base/")){
tuned_linmod01 <- readRDS("../models/base/tuned_linmod01.Rds")
summary(tuned_linmod01) %>% print()
} else {
tuned_linmod01 <- tune(svm ,Class ~ ., data = df_final, kernel = "linear",
ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100) ),
tunecontrol = tune.control(cross=10))
saveRDS(tuned_linmod01,"../models/base/tuned_linmod01.Rds")
tuned_linmod01 <- readRDS("../models/base/tuned_linmod01.Rds")
summary(tuned_linmod01) %>% print()
}
# Modelado inicial con kernel polinomial
if("tuned_polymod01.Rds" %in% list.files("../models/base/")){
tuned_polymod01 <- readRDS("../models/base/tuned_polymod01.Rds")
summary(tuned_polymod01) %>% print()
} else {
tuned_polymod01 <- tune(svm ,Class ~ ., data = df_final, kernel = "polynomial",
ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100) ),
degree = 3,
tunecontrol = tune.control(cross=10))
saveRDS(tuned_polymod01,"../models/base/tuned_polymod01.Rds")
tuned_polymod01 <- readRDS("../models/base/tuned_polymod01.Rds")
summary(tuned_polymod01) %>% print()
}
# Modelado inicial con kernel radial
tuned_radmod01 <- tune(svm ,Class ~ ., data = df_final, kernel = "radial",
ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100) ),
tunecontrol = tune.control(cross=10))
summary(tuned_radmod01) %>% print()
# Modelado inicial con kernel radial
tuned_sigmod01 <- tune(svm ,Class ~ ., data = df_final, kernel = "sigmoid",
ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100) ),
tunecontrol = tune.control(cross=10))
summary(tuned_sigmod01) %>% print()
# Listado de modelos iniciales guardados
saved_models <- list.files("../models/base/")
# Modelado inicial con kernel lineal
if("tuned_linmod01.Rds" %in% list.files("../models/base/")){
tuned_linmod01 <- readRDS("../models/base/tuned_linmod01.Rds")
summary(tuned_linmod01) %>% print()
} else {
tuned_linmod01 <- tune(svm ,Class ~ ., data = df_final, kernel = "linear",
ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100) ),
tunecontrol = tune.control(cross=10))
saveRDS(tuned_linmod01,"../models/base/tuned_linmod01.Rds")
tuned_linmod01 <- readRDS("../models/base/tuned_linmod01.Rds")
summary(tuned_linmod01) %>% print()
}
# Modelado inicial con kernel polinomial
if("tuned_polymod01.Rds" %in% list.files("../models/base/")){
tuned_polymod01 <- readRDS("../models/base/tuned_polymod01.Rds")
summary(tuned_polymod01) %>% print()
} else {
tuned_polymod01 <- tune(svm ,Class ~ ., data = df_final, kernel = "polynomial",
ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100) ),
degree = 3,
tunecontrol = tune.control(cross=10))
saveRDS(tuned_polymod01,"../models/base/tuned_polymod01.Rds")
tuned_polymod01 <- readRDS("../models/base/tuned_polymod01.Rds")
summary(tuned_polymod01) %>% print()
}
# Modelado inicial con kernel radial
if("tuned_radmod01.Rds" %in% list.files("../models/base/")){
tuned_radmod01 <- readRDS("../models/base/tuned_radmod01.Rds")
summary(tuned_radmod01) %>% print()
} else {
tuned_radmod01 <- tune(svm ,Class ~ ., data = df_final, kernel = "radial",
ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100) ),
tunecontrol = tune.control(cross=10))
saveRDS(tuned_radmod01,"../models/base/tuned_radmod01.Rds")
tuned_radmod01 <- readRDS("../models/base/tuned_radmod01.Rds")
summary(tuned_radmod01) %>% print()
}
# Modelado inicial con kernel radial
if("tuned_sigmod01.Rds" %in% list.files("../models/base/")){
tuned_sigmod01 <- readRDS("../models/base/tuned_sigmod01.Rds")
summary(tuned_sigmod01) %>% print()
} else {
tuned_sigmod01 <- tune(svm ,Class ~ ., data = df_final, kernel = "sigmoid",
ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100) ),
tunecontrol = tune.control(cross=10))
saveRDS(tuned_sigmod01,"../models/base/tuned_sigmod01.Rds")
tuned_sigmod01 <- readRDS("../models/base/tuned_sigmod01.Rds")
summary(tuned_sigmod01) %>% print()
}
