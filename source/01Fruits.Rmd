---
title: "Fruits"
author: "Pablo Dominguez"
date: '2022-04-22'
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    collapsed: true
    css: style.css
---

```{r message = FALSE}
library(readxl)
library(dplyr)
library(knitr)
library(ggplot2)
library(ggpubr)
library(pastecs)
library(kableExtra)
```

```{css style settings, echo = FALSE}
blockquote {
    padding: 10px 20px;
    margin: 0 0 20px;
    font-size: 12px;
    border-left: 5px solid #eee;
}
```

# Entrega MACE bloque 2

## Introducción

Por su riqueza en proteínas, carbohidratos, lípidos y minerales las semillas de calabaza son un producto que llega a ser consumido a lo largo de países en todo el mundo. Los factores que determinan el tipo concreto de cada semilla son generalmente relativos a la apariencia externa de la misma. Distinguir el tipo de cada semilla suele requerir experiencia y tiempo, cosa que en nuestro mundo moderno se traduce como un coste económico. 

Con el objetivo de aportar una nueva manera de realizar esta tarea, nos proponemos plantear un algoritmo de clasificación binaria tipo `SVM` que, a partir de la base de datos `Pumpkin_Seeds_Dataset.xlsx`, distinga entre dos categorías diferentes de semillas de calabaza.

Así pues, comenzaremos este estudio con un análisis exploratorio de los datos, para seguir con una construcción de un clasificador a partir de este algoritmo y acabar con una evaluación de los diferentes resultados obtenidos.

## Base de datos

### Presentación de los datos



Tal y como se muestra a continuación, tenemos las dos categorías balanceadas de semillas de calabaza *Çerçevelik* y *Ürgüp Sivrisi*: 

```{r }
options(scipen=999) # desactivamos la notación científica
df <- readxl::read_excel("../dbs/Pumpkin_Seeds_Dataset/Pumpkin_Seeds_Dataset.xlsx")
table(df$Class)
```

> Citation Request :
KOKLU, M., SARIGIL, S., & OZBEK, O. (2021). The use of machine learning methods in classification of pumpkin seeds (Cucurbita pepo L.). Genetic Resources and Crop Evolution, 68(7), 2713-2726. Doi: https://doi.org/10.1007/s10722-021-01226-0

> Puedes conseguir la base de datos en [este enlace](https://www.muratkoklu.com/datasets/Pumpkin_Seeds_Dataset.zip).



### Variables a considerar

En el caso de nuestro estudio, salvo que alguna de las variables tenga poca calidad de dato e introduzca ruido, conservaremos todas para que el modelo disponga de la mayor cantidad de información. El significado de las variables de las que disponemos es por lo general evidente a partir del nombre de la misma. Mostramos a continuación la lista de variables que se han medido para cada muestra, así como el tipo de cada variable en nuestra base de datos:

```{r}
df %>% sapply(class) %>% kable(.,col.names = c("Tipo"))
```

Para continuar con el estudio, analizaremos los valores faltantes y los outliers o valores atípicos, así como presentaremos histogramas comparativos de cada variable  para cada tipo de semilla.

### Calidad del dato

En cuanto a los valores faltantes, tenemos la siguiente información:

```{r}
for(col in df %>% colnames()){
  print(paste0("Hay ",df[col] %>% is.na() %>% sum()," valores faltantes y ",df[col] %>% is.null() %>% sum()," valores nulos en la columna ",col))
}
```

Con lo cual, afortunadamente no tenemos que preocuparnos por técnicas de sustitución o eliminación de valores faltantes o nulos, gracias a que la base de datos está completa.
Comprobemos ahora los valores atípicos. Para ello, pasaremos a presentar un diagrama de cajas y bigotes para cada variable junto con diagramas tipo violin, así como un conteo de este tipo de valores. De este modo, tendremos una mejor visión de la distribución de las variables para cada caso.

```{r out.width="100%"}
ps <- list()
for(colu in df %>% colnames() %>% setdiff(.,"Class")){
  p <- ggplot(df, aes_string(x="Class", y=colu, color="Class")) + geom_violin() + geom_boxplot(width=0.25) + stat_boxplot(geom = "errorbar", width = 0.2) + theme(
    axis.text.x = element_blank(),
    axis.text.y = element_text(size=6),
    axis.title.x = element_text(size = 8),
    axis.title.y = element_text(size = 8),
    legend.key.size = unit(0.1, 'cm'),
    legend.text = element_text(size=8),
    legend.title = element_blank())
  ps[[colu]] <- p
}
ggarrange(plotlist =  ps, nrow = 4,ncol = 3,common.legend = TRUE)
```

Así mismo, (Explicación de los outliers).

Calculamos en primer lugar los estadísticos principales para cada categoría.

```{r}
# Poner nombre primeras columnas (footnote)

# Definimos un df para cada categoría

cat.vec <- df$Class %>% table() %>% names()
df_class01 <- df %>% filter(.,Class == cat.vec[1]) # Çerçevelik
df_class02 <- df %>% filter(.,Class == cat.vec[2]) # Ürgüp Sivrisi

# Calculamos los cuantiles para cada clase

## Clase 1

col_numeric <- which( sapply(df_class01, is.numeric ) ) # Creamos un selector de las columnas numéricas
quantile_df01 <- sapply(col_numeric, function( y ) {
                      quantile( x = unlist( df_class01[,  y ] ), c(.25,.5,.75))
                      }) %>% as.data.frame()
rownames(quantile_df01) <- c("Q1","Q2","Q3")

## Clase 2

col_numeric <- which( sapply(df_class02, is.numeric ) ) # Creamos un selector de las columnas numéricas
quantile_df02 <- sapply(col_numeric, function( y ) {
                      quantile( x = unlist( df_class02[,  y ] ), c(.25,.5,.75))
                      }) %>% as.data.frame()
rownames(quantile_df02) <- c("Q1","Q2","Q3")

# Calculamos el % de outliers para cada clase

## Clase 1

Q1 <- quantile_df01['Q1',] %>% as.vector() %>% as.numeric()
Q3 <- quantile_df01['Q3',] %>% as.vector() %>% as.numeric()
top_IQR <- Q3+1.5*(Q3-Q1) #111027.750000
bot_IQR <- Q1-1.5*(Q3-Q1)
k <- 1
perc_out01 <- c()
for(col in head(colnames(df_class01),-1)){
  count_top_out <- df_class01[col]>=top_IQR[k] %>% as.vector()
  count_bot_out <- df_class01[col]<=bot_IQR[k] %>% as.vector()
  perc_out01 <- c(perc_out01,100*(sum(count_top_out)+sum(count_bot_out))/(df_class01 %>% nrow()))
  k <- k+1
} # el vector perc_out representa el porcentaje de outliers de cada variable.

## Clase 2

Q1 <- quantile_df02['Q1',] %>% as.vector() %>% as.numeric()
Q3 <- quantile_df02['Q3',] %>% as.vector() %>% as.numeric()
top_IQR <- Q3+1.5*(Q3-Q1) 
bot_IQR <- Q1-1.5*(Q3-Q1)
k <- 1
perc_out02 <- c()
for(col in head(colnames(df_class02),-1)){
  count_top_out <- df_class02[col]>=top_IQR[k] %>% as.vector()
  count_bot_out <- df_class02[col]<=bot_IQR[k] %>% as.vector()
  perc_out02 <- c(perc_out02,100*(sum(count_top_out)+sum(count_bot_out))/(df_class02 %>% nrow()))
  k <- k+1
} # el vector perc_out representa el porcentaje de outliers de cada variable.


# Creamos el df final con todos los estadísticos para cada clase

## Calculamos los estadísticos para la clase 1

desc_df01 <- stat.desc(df_class01[,-which(names(df_class01) == "Class")]) %>% slice(., c(4,5,8,9,10,13))  

## Añadimos los porcentajes de outliers para el dataframe de la clase 1

perc_out_class01 <- data.frame(t(perc_out01))
colnames(perc_out_class01) <-  colnames(desc_df01)
rownames(perc_out_class01) <- c("perc.out") #

fn1='Más información sobre los principales estadísticos en ?pastecs::stat.desc.'
#fn2='This is footnote 2 and is much longer'

desc_class01 <- desc_df01 %>%  bind_rows(.,perc_out_class01)
desc_class01  %>% kbl() %>% kable_minimal("hover", full_width = F)%>%
  footnote(c(fn1), general_title="Estadísticos Clase Çerçevelik", title_format = "bold") %>%  scroll_box(width = "auto")
# df %>% kable(., format = "markdown",caption = "This is the table caption")
```

## Modelización con `SVM`

### Modelización inicial

### Propuesta de mejora con menos variables --> Estudiar correlación.

Maria hueles a culo