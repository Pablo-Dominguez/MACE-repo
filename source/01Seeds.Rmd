---
title: "Seeds"
author: "Pablo Dominguez"
date: '`r Sys.Date()`'
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    collapsed: true
    css: style.css
    code_folding: hide
    includes:
      in_header: header.html
---

```{r message = FALSE}
library(readxl)
library(dplyr)
library(knitr)
library(ggplot2)
library(ggpubr)
library(pastecs)
library(kableExtra)
library (e1071)
```

```{css style settings, echo = FALSE}
blockquote {
    padding: 10px 20px;
    margin: 0 0 20px;
    font-size: 12px;
    border-left: 5px solid #eee;
}
```

La información completa sobre la generación de este documento puede encontrarse en este [repositorio de GitHub](https://github.com/Pablo-Dominguez/MACE-repo).

# Entrega MACE bloque 2

## Introducción

Por su riqueza en proteínas, carbohidratos, lípidos y minerales las semillas de calabaza son un producto que llega a ser consumido a lo largo de países en todo el mundo. Los factores que determinan el tipo concreto de cada semilla son generalmente relativos a la apariencia externa de la misma. Distinguir el tipo de cada semilla suele requerir experiencia y tiempo, cosa que en nuestro mundo moderno se traduce como un coste económico. 

Con el objetivo de aportar una nueva manera de realizar esta tarea, nos proponemos plantear un algoritmo de clasificación binaria tipo `SVM` que, a partir de la base de datos `Pumpkin_Seeds_Dataset.xlsx`, distinga entre dos categorías diferentes de semillas de calabaza.

Así pues, comenzaremos este estudio con un análisis exploratorio de los datos, para seguir con una construcción de un clasificador a partir de este algoritmo y acabar con una evaluación de los diferentes resultados obtenidos.

## Base de datos

### Presentación de los datos

Tal y como se muestra a continuación, tenemos las dos categorías balanceadas de semillas de calabaza *Çerçevelik* y *Ürgüp Sivrisi*: 

```{r class.source = 'fold-show'}
options(scipen=999) # desactivamos la notación científica
df <- readxl::read_excel("../dbs/Pumpkin_Seeds_Dataset/Pumpkin_Seeds_Dataset.xlsx")
table(df$Class)
```

> Citation Request :
KOKLU, M., SARIGIL, S., & OZBEK, O. (2021). The use of machine learning methods in classification of pumpkin seeds (Cucurbita pepo L.). Genetic Resources and Crop Evolution, 68(7), 2713-2726. Doi: https://doi.org/10.1007/s10722-021-01226-0

> Puedes conseguir la base de datos en [este enlace](https://www.muratkoklu.com/datasets/Pumpkin_Seeds_Dataset.zip).



### Variables a considerar

En el caso de nuestro estudio, salvo que alguna de las variables tenga poca calidad de dato e introduzca ruido, conservaremos todas para que el modelo disponga de la mayor cantidad de información. El significado de las variables de las que disponemos es por lo general evidente a partir del nombre de la misma. Mostramos a continuación la lista de variables que se han medido para cada muestra, así como el tipo de cada variable en nuestra base de datos:

```{r}
df %>% sapply(class) %>% kable(.,col.names = c("Tipo"))
```

Para continuar con el estudio, analizaremos los valores faltantes y los outliers o valores atípicos, así como presentaremos histogramas comparativos de cada variable  para cada tipo de semilla.

### Calidad del dato

En cuanto a los valores faltantes, tenemos la siguiente información:

```{r}
for(col in df %>% colnames()){
  print(paste0("Hay ",df[col] %>% is.na() %>% sum()," valores faltantes y ",df[col] %>% is.null() %>% sum()," valores nulos en la columna ",col))
}
```

Con lo cual, afortunadamente no tenemos que preocuparnos por técnicas de sustitución o eliminación de valores faltantes o nulos, gracias a que la base de datos está completa.
Comprobemos ahora los valores atípicos. Para ello, pasaremos a presentar un diagrama de cajas y bigotes para cada variable junto con diagramas tipo violin, así como el porcentaje de este tipo de valores junto con los principales estadísticos. De este modo, tendremos una mejor visión de la distribución y el comportamiento de las variables para cada clase de semilla.

```{r out.width="100%"}
ps <- list()
for(colu in df %>% colnames() %>% setdiff(.,"Class")){
  p <- ggplot(df, aes_string(x="Class", y=colu, color="Class")) + geom_violin() + geom_boxplot(width=0.25) + stat_boxplot(geom = "errorbar", width = 0.2) + theme(
    axis.text.x = element_blank(),
    axis.text.y = element_text(size=6),
    axis.title.x = element_text(size = 8),
    axis.title.y = element_text(size = 8),
    legend.key.size = unit(0.1, 'cm'),
    legend.text = element_text(size=8),
    legend.title = element_blank())
  ps[[colu]] <- p
}
ggarrange(plotlist =  ps, nrow = 4,ncol = 3,common.legend = TRUE)
```

Así mismo, existen tres aproximaciones estándar a la hora de tratar este tipo de valores:

1. **Eliminar los outliers**. Esta técnica se recomienda cuando el porcentaje de outliers es muy alto, usualmente en torno al 10%. El motivo de emplear esta técnica es que si un dato tiene muchos outliers, es probable que sean debidos a ruido o mala calidad del dato.
2. **Capado de los outliers**. Se limita el valor máximo y mínimo posible que pueden tomar los valores a dos percentiles dados, por ejemplo al percentil 10 y al 90. Esta técnica es preferible a la anterior por resultar menos agresiva a la hora de impartar sobre el resto de estadísticos.
3. **Sustitución de outliers**. Finalmente, existe la técnica de sustituir los outliers por la mediana. 

A continuación, calculamos los estadísticos principales para cada categoría.

```{r}

# Definimos un df para cada categoría

cat.vec <- df$Class %>% table() %>% names()
df_class01 <- df %>% filter(.,Class == cat.vec[1]) # Çerçevelik
df_class02 <- df %>% filter(.,Class == cat.vec[2]) # Ürgüp Sivrisi

# Calculamos los cuantiles para cada clase

## Clase 1

col_numeric <- which( sapply(df_class01, is.numeric ) ) # Creamos un selector de las columnas numéricas
quantile_df01 <- sapply(col_numeric, function( y ) {
                      quantile( x = unlist( df_class01[,  y ] ), c(.1,.25,.5,.75,.9))
                      }) %>% as.data.frame()
rownames(quantile_df01) <- c("P10","Q1","Q2","Q3","P90")

## Clase 2

col_numeric <- which( sapply(df_class02, is.numeric ) ) # Creamos un selector de las columnas numéricas
quantile_df02 <- sapply(col_numeric, function( y ) {
                      quantile( x = unlist( df_class02[,  y ] ), c(.1,.25,.5,.75,.9))
                      }) %>% as.data.frame()
rownames(quantile_df02) <- c("P10","Q1","Q2","Q3","P90")

# Calculamos el % de outliers para cada clase

## Clase 1

Q1 <- quantile_df01['Q1',] %>% as.vector() %>% as.numeric()
Q3 <- quantile_df01['Q3',] %>% as.vector() %>% as.numeric()
top_IQR <- Q3+1.5*(Q3-Q1) #111027.750000
bot_IQR <- Q1-1.5*(Q3-Q1)
k <- 1
perc_out01 <- c()
for(col in head(colnames(df_class01),-1)){
  count_top_out <- df_class01[col]>=top_IQR[k] %>% as.vector()
  count_bot_out <- df_class01[col]<=bot_IQR[k] %>% as.vector()
  perc_out01 <- c(perc_out01,100*(sum(count_top_out)+sum(count_bot_out))/(df_class01 %>% nrow()))
  k <- k+1
} # el vector perc_out representa el porcentaje de outliers de cada variable.

## Clase 2

Q1 <- quantile_df02['Q1',] %>% as.vector() %>% as.numeric()
Q3 <- quantile_df02['Q3',] %>% as.vector() %>% as.numeric()
top_IQR <- Q3+1.5*(Q3-Q1) 
bot_IQR <- Q1-1.5*(Q3-Q1)
k <- 1
perc_out02 <- c()
for(col in head(colnames(df_class02),-1)){
  count_top_out <- df_class02[col]>=top_IQR[k] %>% as.vector()
  count_bot_out <- df_class02[col]<=bot_IQR[k] %>% as.vector()
  perc_out02 <- c(perc_out02,100*(sum(count_top_out)+sum(count_bot_out))/(df_class02 %>% nrow()))
  k <- k+1
} # el vector perc_out representa el porcentaje de outliers de cada variable.


# Creamos el df final con todos los estadísticos para cada clase

## Calculamos los estadísticos para la clase 1

desc_df01 <- stat.desc(df_class01[,-which(names(df_class01) == "Class")]) %>% slice(., c(4,5,8,9,10,13))  

## Añadimos los porcentajes de outliers para el dataframe de la clase 1

perc_out_class01 <- data.frame(t(perc_out01))
colnames(perc_out_class01) <-  colnames(desc_df01)
rownames(perc_out_class01) <- c("perc.out") #

fn1='Más información sobre los principales estadísticos en `?pastecs::stat.desc`.'
fn2='`perc.out`: Es el porcentaje de outliers para cada variable, según el [criterio de Tukey](https://es.wikipedia.org/wiki/Diagrama_de_caja).'

desc_class01 <- desc_df01 %>%  bind_rows(.,perc_out_class01)
desc_class01  %>% kbl() %>% kable_minimal("hover", full_width = F)%>%
  footnote(number=c(fn1,fn2), number_title="Estadísticos Clase Çerçevelik", title_format = "bold") %>%  scroll_box(width = "auto")

## Calculamos los estadísticos para la clase 2

desc_df02 <- stat.desc(df_class02[,-which(names(df_class02) == "Class")]) %>% slice(., c(4,5,8,9,10,13))  

## Añadimos los porcentajes de outliers para el dataframe de la clase 2

perc_out_class02 <- data.frame(t(perc_out02))
colnames(perc_out_class02) <-  colnames(desc_df02)
rownames(perc_out_class02) <- c("perc.out") #

desc_class02 <- desc_df02 %>%  bind_rows(.,perc_out_class02)
desc_class02  %>% kbl() %>% kable_minimal("hover", full_width = F)%>%
  footnote(c(""),general_title="Estadísticos Clase Ürgüp Sivrisi", title_format = "bold") %>%  scroll_box(width = "auto")
```

<br>
Dado que en ambas categorías la variable que mayor porcentaje de outliers presenta es la `Solidity` con un 4% de outliers,vamos a proceder a sustituirlos por el percentil 10 y el 90, respectivamente y a volver a calcular los estadísticos para comparar si hemos modificado en gran medida la estructura de las variables.


```{r}

# Reemplazamos los outliers para cada clase

## Clase 1

Q1 <- quantile_df01['Q1',] %>% as.vector() %>% as.numeric()
Q3 <- quantile_df01['Q3',] %>% as.vector() %>% as.numeric()
P10 <- quantile_df01['P10',] %>% as.vector() %>% as.numeric()
P90 <- quantile_df01['P90',] %>% as.vector() %>% as.numeric()
top_IQR <- Q3+1.5*(Q3-Q1) #111027.750000
bot_IQR <- Q1-1.5*(Q3-Q1)

trimmed_df_class01 <- data.frame(df_class01)
perc_out01 <- c()
perc_mod01 <- c()
for(i in 1:(ncol(trimmed_df_class01)-1)) { 
  top_mod <- trimmed_df_class01[ , i][trimmed_df_class01[ , i] <= bot_IQR[i]]%>% length()
  bot_mod <- trimmed_df_class01[ , i][trimmed_df_class01[ , i] >= top_IQR[i]]%>% length()
  
  trimmed_df_class01[ , i][trimmed_df_class01[ , i] <= bot_IQR[i]] <- P10[i]
  trimmed_df_class01[ , i][trimmed_df_class01[ , i] >= top_IQR[i]] <- P90[i]
  
  count_top_out <- trimmed_df_class01[ , i]>=top_IQR[i] %>% as.vector()
  count_bot_out <- trimmed_df_class01[ , i]<=bot_IQR[i] %>% as.vector()
  
  perc_out01 <- c(perc_out01,100*(sum(count_top_out)+sum(count_bot_out))/(trimmed_df_class01 %>% nrow()))
  perc_mod01 <- c(perc_mod01,100*(top_mod+bot_mod)/(trimmed_df_class01 %>% nrow()))
  
}# el vector perc_out representa el porcentaje de outliers de cada variable.

## Clase 2

Q1 <- quantile_df02['Q1',] %>% as.vector() %>% as.numeric()
Q3 <- quantile_df02['Q3',] %>% as.vector() %>% as.numeric()
P10 <- quantile_df02['P10',] %>% as.vector() %>% as.numeric()
P90 <- quantile_df02['P90',] %>% as.vector() %>% as.numeric()
top_IQR <- Q3+1.5*(Q3-Q1) #111027.750000
bot_IQR <- Q1-1.5*(Q3-Q1)

trimmed_df_class02 <- data.frame(df_class02)
perc_out02 <- c()
perc_mod02 <- c()
for(i in 1:(ncol(trimmed_df_class02)-1)) { 
  top_mod <- trimmed_df_class02[ , i][trimmed_df_class02[ , i] <= bot_IQR[i]]%>% length()
  bot_mod <- trimmed_df_class02[ , i][trimmed_df_class02[ , i] >= top_IQR[i]]%>% length()
  
  trimmed_df_class02[ , i][trimmed_df_class02[ , i] <= bot_IQR[i]] <- P10[i]
  trimmed_df_class02[ , i][trimmed_df_class02[ , i] >= top_IQR[i]] <- P90[i]
  
  count_top_out <- trimmed_df_class02[ , i]>=top_IQR[i] %>% as.vector()
  count_bot_out <- trimmed_df_class02[ , i]<=bot_IQR[i] %>% as.vector()
  
  perc_out02 <- c(perc_out02,100*(sum(count_top_out)+sum(count_bot_out))/(trimmed_df_class02 %>% nrow()))
  perc_mod02 <- c(perc_mod02,100*(top_mod+bot_mod)/(trimmed_df_class02 %>% nrow()))
  
}# el vector perc_out representa el porcentaje de outliers de cada variable.

# Creamos el df final con todos los estadísticos para cada clase

## Calculamos los estadísticos para la clase 1

desc_df01 <- stat.desc(trimmed_df_class01[,-which(names(trimmed_df_class01) == "Class")]) %>% slice(., c(4,5,8,9,10,13))  

## Añadimos los porcentajes de outliers y el porcentaje de valores modificados para el dataframe de la clase 1

perc_out_class01 <- data.frame(t(perc_out01))
colnames(perc_out_class01) <-  colnames(desc_df01)
rownames(perc_out_class01) <- c("perc.out") #

perc_mod_class01 <- data.frame(t(perc_mod01))
colnames(perc_mod_class01) <-  colnames(desc_df01)
rownames(perc_mod_class01) <- c("perc.mod") #

fn2='`perc.mod`: Es el porcentaje de valores modificados para cada variable.'

desc_class01 <- desc_df01 %>%  bind_rows(.,perc_out_class01) %>% bind_rows(.,perc_mod_class01)
desc_class01  %>% kbl() %>% kable_minimal("hover", full_width = F)%>%
  footnote(number=c(fn2), number_title ="Estadísticos Clase Çerçevelik - Modificado", title_format = "bold") %>%  scroll_box(width = "auto")

## Calculamos los estadísticos para la clase 2

desc_df02 <- stat.desc(trimmed_df_class02[,-which(names(trimmed_df_class02) == "Class")]) %>% slice(., c(4,5,8,9,10,13))  

## Añadimos los porcentajes de outliers para el dataframe de la clase 2

perc_out_class02 <- data.frame(t(perc_out02))
colnames(perc_out_class02) <-  colnames(desc_df02)
rownames(perc_out_class02) <- c("perc.out") #

perc_mod_class02 <- data.frame(t(perc_mod02))
colnames(perc_mod_class02) <-  colnames(desc_df02)
rownames(perc_mod_class02) <- c("perc.mod") #

desc_class02 <- desc_df02 %>%  bind_rows(.,perc_out_class02)%>% bind_rows(.,perc_mod_class02)
desc_class02  %>% kbl() %>% kable_minimal("hover", full_width = F)%>%
  footnote(c(""),general_title="Estadísticos Clase Ürgüp Sivrisi - Modificado", title_format = "bold") %>%  scroll_box(width = "auto")

```

<br>
Como se puede observar respectivamente en cada tabla, hemos eliminado en todos los casos los outliers al tiempo que no hemos afectado significativamente el resto de estadísticos. Emplearemos por tanto esta base de datos modificada como base de datos de partida para el proceso del modelado de los datos.

```{r class.source = 'fold-show'}
# Creación de la base de datos para el modelado.
df_final <- trimmed_df_class01 %>% bind_rows(.,trimmed_df_class02)
```


## Modelización con `SVM`

### Modelización inicial

En primer lugar, debemos configurar la variable `Class` para que nuestro modelo la considere como un factor.

```{r class.source = 'fold-show'}
df_final$Class <- as.factor(df_final$Class)
```

A continuación, vamos a crear una serie de modelos con los que iniciaremos nuestra fase de modelado. Crearemos cuatro tuneados, uno para cada tipo de kernel, con un vector inicial de costes con los valores `0.001, 0.01, 0.1, 1, 5, 10, 100` y 10 pliegues de validación cruzada. De entre ellos, seleccionaremos los dos tipos kernels que arrojen mejores resultados y haremos un tuneo más en profundidad sobre los hiperparámetros de cada tipo de modelo respectivamente.

Cabe destacar en esta parte del proceso dos puntos sobre los modelos que presentamos a continuación. Por una parte, en general la búsqueda de hiperparámetros es un proceso costoso, sobre todo en términos de tiempo de computación, por lo que el siguiente bloque de código se limita a cargar los modelos que están almacenados en [la carpeta](github.com/Pablo-Dominguez/MACE-repo/tree/main/models/base) `models/base` previamente ejecutados. De esta forma, podemos generar el presente documento sin necesidad de reentrenar los modelos cada vez.
Por otro lado, debido además a que nuestro ámbito de estudio se centra en presentar las capacidades de `SVM`, no realizaremos una búsqueda exhaustiva de los hiperparámetros óptimos, ya que este es un proceso que en términos de tiempo de computación se escapa del alcance de este documento.

```{r}

# Listado de modelos iniciales guardados

saved_models <- list.files("../models/base/")

# Modelado inicial con kernel lineal

if("tuned_linmod01.Rds" %in% list.files("../models/base/")){
  tuned_linmod01 <- readRDS("../models/base/tuned_linmod01.Rds")
  summary(tuned_linmod01) %>% print()
} else {
  tuned_linmod01 <- tune(svm ,Class ~ ., data = df_final, kernel = "linear",
                       ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100) ),
                       tunecontrol = tune.control(cross=10))
  saveRDS(tuned_linmod01,"../models/base/tuned_linmod01.Rds")
  tuned_linmod01 <- readRDS("../models/base/tuned_linmod01.Rds")
  summary(tuned_linmod01) %>% print()
}

# Modelado inicial con kernel polinomial

if("tuned_polymod01.Rds" %in% list.files("../models/base/")){
  tuned_polymod01 <- readRDS("../models/base/tuned_polymod01.Rds")
  print(summary(tuned_polymod01))
} else {
  tuned_polymod01 <- tune(svm ,Class ~ ., data = df_final, kernel = "polynomial",
                       ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100) ),
                       degree = 3,
                       tunecontrol = tune.control(cross=10))
  saveRDS(tuned_polymod01,"../models/base/tuned_polymod01.Rds")
  tuned_polymod01 <- readRDS("../models/base/tuned_polymod01.Rds")
  print(summary(tuned_polymod01))
}


# Modelado inicial con kernel radial

if("tuned_radmod01.Rds" %in% list.files("../models/base/")){
  tuned_radmod01 <- readRDS("../models/base/tuned_radmod01.Rds")
  summary(tuned_radmod01) %>% print()
} else {
  tuned_radmod01 <- tune(svm ,Class ~ ., data = df_final, kernel = "radial",
                       ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100) ),
                       tunecontrol = tune.control(cross=10))
  saveRDS(tuned_radmod01,"../models/base/tuned_radmod01.Rds")
  tuned_radmod01 <- readRDS("../models/base/tuned_radmod01.Rds")
  summary(tuned_radmod01) %>% print()
}

# Modelado inicial con kernel radial

if("tuned_sigmod01.Rds" %in% list.files("../models/base/")){
  tuned_sigmod01 <- readRDS("../models/base/tuned_sigmod01.Rds")
  summary(tuned_sigmod01) %>% print()
} else {
  tuned_sigmod01 <- tune(svm ,Class ~ ., data = df_final, kernel = "sigmoid",
                       ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100) ),
                       tunecontrol = tune.control(cross=10))
  saveRDS(tuned_sigmod01,"../models/base/tuned_sigmod01.Rds")
  tuned_sigmod01 <- readRDS("../models/base/tuned_sigmod01.Rds")
  summary(tuned_sigmod01) %>% print()
}

```


### Propuesta de mejora con menos variables --> Estudiar correlación.

